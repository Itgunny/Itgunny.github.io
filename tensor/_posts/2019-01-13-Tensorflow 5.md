## ML로 전환하기

오랫동안 귀뚜라미는 시원날 날보다 더운 날 더 자주 우는 것으로 알려져 왔습니다. 전문가 및 아마추어 곤충 학자들이 수십 년에 걸쳐서 1분 당 귀뚜라미가 우는 횟수와 온도에 관한 데이터를 목록으로 작성했습니다. 

올바른 첫 번째 단계는 데이터를 그래프로 만들어 검토하는 것입니다. 

![분당 처프 (x 축) 대 온도 (y 축)의 원시 데이터입니다.](https://developers.google.com/machine-learning/crash-course/images/CricketPoints.svg?hl=ko)

그림 1.1분당 우는 횟수 및 섭씨 온도. {: .text-center}

예상대로 그래프를 통해 우는 횟수가 증가할수록 온도가 올라가는 것을 확인했습니다. 아래와 같이 보면 데이터를 보고 하나의 직선을 그릴 수 있습니다. 이러한 관계를 선형 관계라고 합니다. 

![분당 짹짹 (x 축) 대 온도 (y 축)의 관계를 설정하는 최고의 라인.](https://developers.google.com/machine-learning/crash-course/images/CricketLine.svg?hl=ko)

그림 2. 선형 관계 {: .text-center}

사실 선이 모든 점을 완벽하게 통과하지는 않지만, 선은 우리에게 있는 온도 데이터와 우는 소리 데이터의 관계를 명확히 보여줍니다. 대수학을 약간 적용하면 이 관계를 다음과 같이 작성가능 하다. 

$y' = mx + b​$ {: .text-center}



여기서  

- y는 섭씨온도, 즉 예측하려는 값입니다.
- m은 선의 기울기입니다. 
- x는 1분당 우는 횟수, 즉 입력 특성 값입니다. 
- b는 y절편입니다. 

머신러닝의 관습에 따라 모델의 방적식을 약간 다르게 작성하게 됩니다. 

$y' = b + w_1x_1$ {: .text-center}

여기서 

- y'는 예측된 라벨(얻고자 하는 출력)입니다. 
- b는 편향(y절편)입니다. 일부 머신러닝 자료에서는 w0이라고도 합니다. 
- w1은 특성 1의 가중치입니다. 가중치는 위에서 m으로 표현된 '기울기'와 같은 개념입니다. 
- x1은 특성(알려진 입력)입니다. 

새로운 분당 우는 횟수 x1에서 온도 y'를 추론(예측) 하려면 x1 값을 이 모델에 삽입하기만 하면 됩니다. 

아래 첨자(예:w1, x1)는 여러 특성에 의존하는 좀 더 정교한 모델을 예시합니다. 예를 들어 세가지 특성에 의존하는 모델은 다음과 같은 방정식을 사용합니다. 

$y' = b + w_1x_1 + w_2x_2 + w_3x_3$ {: .text-center}

## ML로 전환하기 : 학습 및 손실

모델을 학습시킨다는 것은 단순히 말하자면 라벨이 있는 데이터로부터 올바른 가중치와 편향값을 학습하는 것입니다. 다양한 예를 검토하고 손실을 최소화 하는 모델을 찾아봄으로써 모델을 만들어 내는데 empirical risk minimization(경험적 위험 최소화) 라고 합니다. 

손실은 잘못된 예측에 대한 수치입니다. 즉, 손실은 한 가지 예에서 모델의 예측이 얼마나 잘못되었는 지를 나타내는 수 입니다. 모델의 예측이 완벽하면 손실은 0이고 그렇지 않으면 손실은 그보다 커집니다. 모델 학습의 목표는 모든 예에서 평균적으로 작은 손실을 갖는 가중치의 편향의 집합을 찾는 것입니다. 

예를 들어 그림 3에서 왼쪽은 손실이 큰 모델이고, 오른쪽은 손실이 작은 모델입니다. 따라서 

- 빨간색 화살표는 손실을 나타내고, 파란색 직서은 예측을 나타 냅니다. 

![각각 직선과 일부 데이터 포인트를 나타내고 있는 두 개의 데카르트 그래프 첫 번째 그래프에서 직선은 데이터와 거의 일치하지 않으므로 손실이 높습니다. 두 번째 그래프에서 직선은 데이터와 많이 일치하므로 손실이 낮습니다.](https://developers.google.com/machine-learning/crash-course/images/LossSideBySide.png?hl=ko)

그림 3. 왼쪽모델은 손실이 크고 오른쪽 모델은 손실이 작음 {: .text-center}

보다 시피 왼쪽 그래프에서 손실 값이 오른쪽 보다 더 크다는 것을 알 수 있고 따라서 예측을 잘하는 모델은 오른쪽이 됩니다.

손실을 수학적으로 표현할 수 있는 능력이 필요합니다. 

```
= the square of the difference between the label and the prediction
= (observation - prediction(x))^2
= (y - y')^2
```

평균 제곱 오차(MSE)는 예시당 평균 제곱 손실입니다. MSE를 계산하려면 개별 예의 모든 제곱 손실을 합한 다음 예의 수로 나눕니다. 

$MSE = 1/N\sum_{(x,y\in D)} (y - prediction(x))^2$ : {: .text-center}

여기서 

- (x, y)는 예이며, 다음과 같습니다. 

  x는 모델이 예측하는 데 사용하는 특정 집합(예: 온도, 나이, 짝짓기 성공률)입니다. 

  y는 예의 라벨입니다. 

- prediction(x)은 특성 집합x과 결합된 가중치 및 편향의 함수입니다.
- D는 (x, y) 쌍과 같이 여러 라벨이 있는 예가 포함된 데이터 시트입니다. 
- N은 D에 포함된 예의 수입니다. 

MSE는 머신러닝에서 흔히 사용되지만, 모든 상황에서 최선인 유일한 손실 함수는 아닙니다. 



